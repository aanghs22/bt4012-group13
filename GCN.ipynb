{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data(x=[20302, 22], edge_index=[2, 197481], y=[20302], train_mask=[20302], val_mask=[20302], test_mask=[20302])"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "account_df = pd.read_csv('data/processed/kaggle_transaction_dataset_centrality.csv')\n",
        "address_mapping = pd.DataFrame(data={\n",
        "    'address': account_df['address'], \n",
        "    'mapped_id': account_df['address'].index\n",
        "})\n",
        "\n",
        "transaction_df = pd.read_csv('data/queried/full_transactions.csv')\n",
        "transaction_mapping = transaction_df \\\n",
        "    .merge(\n",
        "        address_mapping, \n",
        "        left_on='address from', \n",
        "        right_on='address'\n",
        "    ) \\\n",
        "    .merge(\n",
        "        address_mapping, \n",
        "        left_on='address to', \n",
        "        right_on='address', \n",
        "        suffixes=('_from', '_to')\n",
        "    )\n",
        "\n",
        "x = F.normalize(\n",
        "    torch.tensor(\n",
        "        account_df.drop(columns=['address', 'flag']).to_numpy(), \n",
        "        dtype=torch.float\n",
        "    )\n",
        ")\n",
        "y = torch.tensor(\n",
        "    account_df['flag'].to_numpy(), \n",
        "    dtype=torch.long\n",
        ")\n",
        "edge_index = torch.tensor(\n",
        "    transaction_mapping[['mapped_id_from', 'mapped_id_to']].to_numpy().T, \n",
        "    dtype=torch.long\n",
        ")\n",
        "\n",
        "data = Data(x=x, y=y, edge_index=edge_index)\n",
        "data = T.ToUndirected()(data)\n",
        "data = T.RandomNodeSplit(num_val=0, num_test=2000)(data)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Weights: tensor([0.6940, 1.7887])\n"
          ]
        }
      ],
      "source": [
        "classes, counts = torch.unique(y, return_counts=True)\n",
        "\n",
        "# Calculate class weights based on their frequency\n",
        "total_samples = torch.sum(counts).float()\n",
        "class_weights = total_samples / (classes.numel() * counts.float())\n",
        "\n",
        "print(\"Class Weights:\", class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, GCNConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(data.num_node_features, 64)\n",
        "        self.conv2 = GCNConv(64, 64)\n",
        "        self.conv3 = GCNConv(64, 2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, heads=4):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(data.num_node_features, 32, heads=heads)\n",
        "        self.conv2 = GATConv(32 * heads, 32, heads=heads)\n",
        "        self.conv3 = GATConv(32 * heads, 2, heads=1)  # Last layer typically uses a single head\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "\n",
        "def get_results(model, data):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    data = data.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(251):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask], weight=class_weights)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if epoch % 10 == 0:\n",
        "            pred = model(data).argmax(dim=1)\n",
        "            correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
        "            acc = int(correct) / int(data.test_mask.sum())\n",
        "            f1 = f1_score(data.y[data.test_mask], pred[data.test_mask], average='weighted')\n",
        "            auroc = roc_auc_score(data.y[data.test_mask], pred[data.test_mask])\n",
        "            print(f'Epoch {str(epoch).zfill(3)}: Accuracy {acc:.3f} F1 Score {f1:.3f} AUROC: {auroc:.3f}')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 000: Accuracy 0.590 F1 Score 0.606 AUROC: 0.660\n",
            "Epoch 010: Accuracy 0.762 F1 Score 0.771 AUROC: 0.757\n",
            "Epoch 020: Accuracy 0.802 F1 Score 0.809 AUROC: 0.805\n",
            "Epoch 030: Accuracy 0.858 F1 Score 0.861 AUROC: 0.851\n",
            "Epoch 040: Accuracy 0.859 F1 Score 0.863 AUROC: 0.857\n",
            "Epoch 050: Accuracy 0.864 F1 Score 0.867 AUROC: 0.864\n",
            "Epoch 060: Accuracy 0.869 F1 Score 0.871 AUROC: 0.858\n",
            "Epoch 070: Accuracy 0.876 F1 Score 0.878 AUROC: 0.866\n",
            "Epoch 080: Accuracy 0.858 F1 Score 0.861 AUROC: 0.858\n",
            "Epoch 090: Accuracy 0.868 F1 Score 0.871 AUROC: 0.862\n",
            "Epoch 100: Accuracy 0.884 F1 Score 0.886 AUROC: 0.873\n",
            "Epoch 110: Accuracy 0.872 F1 Score 0.874 AUROC: 0.860\n",
            "Epoch 120: Accuracy 0.876 F1 Score 0.879 AUROC: 0.867\n",
            "Epoch 130: Accuracy 0.858 F1 Score 0.862 AUROC: 0.855\n",
            "Epoch 140: Accuracy 0.867 F1 Score 0.870 AUROC: 0.867\n",
            "Epoch 150: Accuracy 0.879 F1 Score 0.882 AUROC: 0.877\n",
            "Epoch 160: Accuracy 0.872 F1 Score 0.875 AUROC: 0.875\n",
            "Epoch 170: Accuracy 0.879 F1 Score 0.881 AUROC: 0.866\n",
            "Epoch 180: Accuracy 0.875 F1 Score 0.878 AUROC: 0.878\n",
            "Epoch 190: Accuracy 0.880 F1 Score 0.882 AUROC: 0.869\n",
            "Epoch 200: Accuracy 0.881 F1 Score 0.883 AUROC: 0.873\n",
            "Epoch 210: Accuracy 0.890 F1 Score 0.892 AUROC: 0.882\n",
            "Epoch 220: Accuracy 0.892 F1 Score 0.893 AUROC: 0.882\n",
            "Epoch 230: Accuracy 0.873 F1 Score 0.876 AUROC: 0.870\n",
            "Epoch 240: Accuracy 0.880 F1 Score 0.882 AUROC: 0.868\n",
            "Epoch 250: Accuracy 0.875 F1 Score 0.878 AUROC: 0.874\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GCN(\n",
              "  (conv1): GCNConv(22, 64)\n",
              "  (conv2): GCNConv(64, 64)\n",
              "  (conv3): GCNConv(64, 2)\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_results(GCN(), data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 000: Accuracy 0.671 F1 Score 0.682 AUROC: 0.642\n",
            "Epoch 010: Accuracy 0.798 F1 Score 0.802 AUROC: 0.771\n",
            "Epoch 020: Accuracy 0.849 F1 Score 0.851 AUROC: 0.826\n",
            "Epoch 030: Accuracy 0.872 F1 Score 0.873 AUROC: 0.853\n",
            "Epoch 040: Accuracy 0.893 F1 Score 0.892 AUROC: 0.863\n",
            "Epoch 050: Accuracy 0.875 F1 Score 0.877 AUROC: 0.866\n",
            "Epoch 060: Accuracy 0.895 F1 Score 0.895 AUROC: 0.874\n",
            "Epoch 070: Accuracy 0.894 F1 Score 0.895 AUROC: 0.878\n",
            "Epoch 080: Accuracy 0.870 F1 Score 0.873 AUROC: 0.869\n",
            "Epoch 090: Accuracy 0.900 F1 Score 0.901 AUROC: 0.879\n",
            "Epoch 100: Accuracy 0.900 F1 Score 0.902 AUROC: 0.888\n",
            "Epoch 110: Accuracy 0.887 F1 Score 0.890 AUROC: 0.896\n",
            "Epoch 120: Accuracy 0.889 F1 Score 0.892 AUROC: 0.897\n",
            "Epoch 130: Accuracy 0.909 F1 Score 0.910 AUROC: 0.895\n",
            "Epoch 140: Accuracy 0.903 F1 Score 0.905 AUROC: 0.903\n",
            "Epoch 150: Accuracy 0.905 F1 Score 0.907 AUROC: 0.906\n",
            "Epoch 160: Accuracy 0.913 F1 Score 0.914 AUROC: 0.899\n",
            "Epoch 170: Accuracy 0.905 F1 Score 0.907 AUROC: 0.899\n",
            "Epoch 180: Accuracy 0.920 F1 Score 0.921 AUROC: 0.917\n",
            "Epoch 190: Accuracy 0.887 F1 Score 0.891 AUROC: 0.901\n",
            "Epoch 200: Accuracy 0.917 F1 Score 0.919 AUROC: 0.914\n",
            "Epoch 210: Accuracy 0.889 F1 Score 0.892 AUROC: 0.903\n",
            "Epoch 220: Accuracy 0.905 F1 Score 0.907 AUROC: 0.910\n",
            "Epoch 230: Accuracy 0.883 F1 Score 0.887 AUROC: 0.902\n",
            "Epoch 240: Accuracy 0.904 F1 Score 0.907 AUROC: 0.916\n",
            "Epoch 250: Accuracy 0.910 F1 Score 0.912 AUROC: 0.910\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GAT(\n",
              "  (conv1): GATConv(22, 32, heads=4)\n",
              "  (conv2): GATConv(128, 32, heads=4)\n",
              "  (conv3): GATConv(128, 2, heads=1)\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_results(GAT(), data)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
