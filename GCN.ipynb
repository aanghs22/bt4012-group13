{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "account_df = pd.read_csv('data/processed/kaggle_transaction_dataset_centrality.csv')\n",
        "address_mapping = pd.DataFrame(data={\n",
        "    'address': account_df['address'], \n",
        "    'mapped_id': account_df['address'].index\n",
        "})\n",
        "\n",
        "transaction_df = pd.read_csv('data/queried/full_transactions.csv')\n",
        "transaction_mapping = transaction_df \\\n",
        "    .merge(\n",
        "        address_mapping, \n",
        "        left_on='address from', \n",
        "        right_on='address'\n",
        "    ) \\\n",
        "    .merge(\n",
        "        address_mapping, \n",
        "        left_on='address to', \n",
        "        right_on='address', \n",
        "        suffixes=('_from', '_to')\n",
        "    )\n",
        "\n",
        "x = F.normalize(\n",
        "    torch.tensor(\n",
        "        account_df.drop(columns=['address', 'flag']).to_numpy(), \n",
        "        dtype=torch.float\n",
        "    )\n",
        ")\n",
        "y = torch.tensor(\n",
        "    account_df['flag'].to_numpy(), \n",
        "    dtype=torch.long\n",
        ")\n",
        "edge_index = torch.tensor(\n",
        "    transaction_mapping[['mapped_id_from', 'mapped_id_to']].to_numpy(), \n",
        "    dtype=torch.long\n",
        ")\n",
        "\n",
        "data = Data(x=x, y=y, edge_index=edge_index)\n",
        "data = T.ToUndirected()(data)\n",
        "data = T.RandomNodeSplit(num_val=0, num_test=2000)(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Weights: tensor([0.6940, 1.7887])\n"
          ]
        }
      ],
      "source": [
        "classes, counts = torch.unique(y, return_counts=True)\n",
        "\n",
        "# Calculate class weights based on their frequency\n",
        "total_samples = torch.sum(counts).float()\n",
        "class_weights = total_samples / (classes.numel() * counts.float())\n",
        "\n",
        "print(\"Class Weights:\", class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, GCNConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(data.num_node_features, 64)\n",
        "        self.conv2 = GCNConv(64, 64)\n",
        "        self.conv3 = GCNConv(64, 2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, heads=4):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(data.num_node_features, 32, heads=heads)\n",
        "        self.conv2 = GATConv(32 * heads, 32, heads=heads)\n",
        "        self.conv3 = GATConv(32 * heads, 2, heads=1)  # Last layer typically uses a single head\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 000: Accuracy 0.612 F1 Score 0.631 AUROC: 0.668\n",
            "Epoch 010: Accuracy 0.676 F1 Score 0.693 AUROC: 0.749\n",
            "Epoch 020: Accuracy 0.683 F1 Score 0.699 AUROC: 0.764\n",
            "Epoch 030: Accuracy 0.684 F1 Score 0.700 AUROC: 0.769\n",
            "Epoch 040: Accuracy 0.684 F1 Score 0.699 AUROC: 0.770\n",
            "Epoch 050: Accuracy 0.688 F1 Score 0.703 AUROC: 0.771\n",
            "Epoch 060: Accuracy 0.689 F1 Score 0.703 AUROC: 0.778\n",
            "Epoch 070: Accuracy 0.680 F1 Score 0.695 AUROC: 0.770\n",
            "Epoch 080: Accuracy 0.684 F1 Score 0.699 AUROC: 0.775\n",
            "Epoch 090: Accuracy 0.688 F1 Score 0.702 AUROC: 0.774\n",
            "Epoch 100: Accuracy 0.684 F1 Score 0.699 AUROC: 0.772\n",
            "Epoch 110: Accuracy 0.685 F1 Score 0.700 AUROC: 0.775\n",
            "Epoch 120: Accuracy 0.686 F1 Score 0.701 AUROC: 0.774\n",
            "Epoch 130: Accuracy 0.687 F1 Score 0.702 AUROC: 0.775\n",
            "Epoch 140: Accuracy 0.684 F1 Score 0.699 AUROC: 0.772\n",
            "Epoch 150: Accuracy 0.689 F1 Score 0.703 AUROC: 0.776\n",
            "Epoch 160: Accuracy 0.688 F1 Score 0.703 AUROC: 0.774\n",
            "Epoch 170: Accuracy 0.689 F1 Score 0.704 AUROC: 0.776\n",
            "Epoch 180: Accuracy 0.690 F1 Score 0.705 AUROC: 0.775\n",
            "Epoch 190: Accuracy 0.695 F1 Score 0.710 AUROC: 0.779\n",
            "Epoch 200: Accuracy 0.689 F1 Score 0.703 AUROC: 0.774\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GAT().to(device)\n",
        "data = data.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(201):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask], weight=class_weights)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "        pred = model(data).argmax(dim=1)\n",
        "        correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
        "        acc = int(correct) / int(data.test_mask.sum())\n",
        "        f1 = f1_score(data.y[data.test_mask], pred[data.test_mask], average='weighted')\n",
        "        auroc = roc_auc_score(data.y[data.test_mask], pred[data.test_mask])\n",
        "        print(f'Epoch {str(epoch).zfill(3)}: Accuracy {acc:.3f} F1 Score {f1:.3f} AUROC: {auroc:.3f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
