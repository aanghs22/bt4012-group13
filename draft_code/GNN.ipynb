{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data(x=[20302, 22], edge_index=[2, 197481], y=[20302], train_mask=[20302], val_mask=[20302], test_mask=[20302])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "account_df = pd.read_csv('data/processed/kaggle_transaction_dataset_centrality.csv')\n",
        "address_mapping = pd.DataFrame(data={\n",
        "    'address': account_df['address'], \n",
        "    'mapped_id': account_df['address'].index\n",
        "})\n",
        "\n",
        "transaction_df = pd.read_csv('data/queried/full_transactions.csv')\n",
        "transaction_mapping = transaction_df \\\n",
        "    .merge(\n",
        "        address_mapping, \n",
        "        left_on='address from', \n",
        "        right_on='address'\n",
        "    ) \\\n",
        "    .merge(\n",
        "        address_mapping, \n",
        "        left_on='address to', \n",
        "        right_on='address', \n",
        "        suffixes=('_from', '_to')\n",
        "    )\n",
        "\n",
        "x = F.normalize(\n",
        "    torch.tensor(\n",
        "        account_df.drop(columns=['address', 'flag']).to_numpy(), \n",
        "        dtype=torch.float\n",
        "    )\n",
        ")\n",
        "y = torch.tensor(\n",
        "    account_df['flag'].to_numpy(), \n",
        "    dtype=torch.long\n",
        ")\n",
        "edge_index = torch.tensor(\n",
        "    transaction_mapping[['mapped_id_from', 'mapped_id_to']].to_numpy().T, \n",
        "    dtype=torch.long\n",
        ")\n",
        "\n",
        "data = Data(x=x, y=y, edge_index=edge_index)\n",
        "data = T.ToUndirected()(data)\n",
        "data = T.RandomNodeSplit(num_val=0, num_test=2000)(data)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Weights: tensor([0.6940, 1.7887])\n"
          ]
        }
      ],
      "source": [
        "classes, counts = torch.unique(y, return_counts=True)\n",
        "\n",
        "# Calculate class weights based on their frequency\n",
        "total_samples = torch.sum(counts).float()\n",
        "class_weights = total_samples / (classes.numel() * counts.float())\n",
        "\n",
        "print(\"Class Weights:\", class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, GCNConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(data.num_node_features, 64)\n",
        "        self.conv2 = GCNConv(64, 64)\n",
        "        self.conv3 = GCNConv(64, 2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, heads=4):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(data.num_node_features, 32, heads=heads)\n",
        "        self.conv2 = GATConv(32 * heads, 32, heads=heads)\n",
        "        self.conv3 = GATConv(32 * heads, 2, heads=1)  # Last layer typically uses a single head\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "def get_results(model, data):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    data = data.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(251):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask], weight=class_weights)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if epoch % 10 == 0:\n",
        "            pred = model(data).argmax(dim=1)\n",
        "            correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
        "            acc = int(correct) / int(data.test_mask.sum())\n",
        "            precision = precision_score(data.y[data.test_mask], pred[data.test_mask], average='weighted')\n",
        "            recall = recall_score(data.y[data.test_mask], pred[data.test_mask], average='weighted')\n",
        "            f1 = f1_score(data.y[data.test_mask], pred[data.test_mask], average='weighted')\n",
        "            auroc = roc_auc_score(data.y[data.test_mask], pred[data.test_mask])\n",
        "            print(f'Epoch {str(epoch).zfill(3)}: Accuracy {acc:.3f} Precision: {precision:.3f} Recall: {recall:.3f} F1 Score {f1:.3f} AUROC: {auroc:.3f}')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 000: Accuracy 0.552 Precision: 0.753 Recall: 0.552 F1 Score 0.568 AUROC: 0.650\n",
            "Epoch 010: Accuracy 0.754 Precision: 0.797 Recall: 0.754 F1 Score 0.765 AUROC: 0.755\n",
            "Epoch 020: Accuracy 0.818 Precision: 0.839 Recall: 0.818 F1 Score 0.824 AUROC: 0.811\n",
            "Epoch 030: Accuracy 0.861 Precision: 0.872 Recall: 0.861 F1 Score 0.864 AUROC: 0.852\n",
            "Epoch 040: Accuracy 0.874 Precision: 0.881 Recall: 0.874 F1 Score 0.876 AUROC: 0.859\n",
            "Epoch 050: Accuracy 0.883 Precision: 0.889 Recall: 0.883 F1 Score 0.885 AUROC: 0.868\n",
            "Epoch 060: Accuracy 0.881 Precision: 0.888 Recall: 0.881 F1 Score 0.883 AUROC: 0.869\n",
            "Epoch 070: Accuracy 0.887 Precision: 0.895 Recall: 0.887 F1 Score 0.889 AUROC: 0.879\n",
            "Epoch 080: Accuracy 0.892 Precision: 0.895 Recall: 0.892 F1 Score 0.893 AUROC: 0.873\n",
            "Epoch 090: Accuracy 0.886 Precision: 0.892 Recall: 0.886 F1 Score 0.888 AUROC: 0.874\n",
            "Epoch 100: Accuracy 0.892 Precision: 0.900 Recall: 0.892 F1 Score 0.894 AUROC: 0.886\n",
            "Epoch 110: Accuracy 0.882 Precision: 0.892 Recall: 0.882 F1 Score 0.885 AUROC: 0.878\n",
            "Epoch 120: Accuracy 0.881 Precision: 0.894 Recall: 0.881 F1 Score 0.885 AUROC: 0.882\n",
            "Epoch 130: Accuracy 0.888 Precision: 0.900 Recall: 0.888 F1 Score 0.891 AUROC: 0.889\n",
            "Epoch 140: Accuracy 0.888 Precision: 0.898 Recall: 0.888 F1 Score 0.891 AUROC: 0.885\n",
            "Epoch 150: Accuracy 0.897 Precision: 0.904 Recall: 0.897 F1 Score 0.899 AUROC: 0.890\n",
            "Epoch 160: Accuracy 0.893 Precision: 0.900 Recall: 0.893 F1 Score 0.896 AUROC: 0.886\n",
            "Epoch 170: Accuracy 0.890 Precision: 0.903 Recall: 0.890 F1 Score 0.893 AUROC: 0.895\n",
            "Epoch 180: Accuracy 0.881 Precision: 0.893 Recall: 0.881 F1 Score 0.885 AUROC: 0.880\n",
            "Epoch 190: Accuracy 0.887 Precision: 0.895 Recall: 0.887 F1 Score 0.890 AUROC: 0.880\n",
            "Epoch 200: Accuracy 0.888 Precision: 0.900 Recall: 0.888 F1 Score 0.891 AUROC: 0.889\n",
            "Epoch 210: Accuracy 0.885 Precision: 0.898 Recall: 0.885 F1 Score 0.889 AUROC: 0.887\n",
            "Epoch 220: Accuracy 0.893 Precision: 0.903 Recall: 0.893 F1 Score 0.896 AUROC: 0.892\n",
            "Epoch 230: Accuracy 0.897 Precision: 0.901 Recall: 0.897 F1 Score 0.898 AUROC: 0.883\n",
            "Epoch 240: Accuracy 0.893 Precision: 0.901 Recall: 0.893 F1 Score 0.895 AUROC: 0.887\n",
            "Epoch 250: Accuracy 0.889 Precision: 0.897 Recall: 0.889 F1 Score 0.892 AUROC: 0.881\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GCN(\n",
              "  (conv1): GCNConv(22, 64)\n",
              "  (conv2): GCNConv(64, 64)\n",
              "  (conv3): GCNConv(64, 2)\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_results(GCN(), data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 000: Accuracy 0.617 Precision: 0.740 Recall: 0.617 F1 Score 0.639 AUROC: 0.664\n",
            "Epoch 010: Accuracy 0.818 Precision: 0.831 Recall: 0.818 F1 Score 0.822 AUROC: 0.796\n",
            "Epoch 020: Accuracy 0.845 Precision: 0.857 Recall: 0.845 F1 Score 0.849 AUROC: 0.831\n",
            "Epoch 030: Accuracy 0.875 Precision: 0.877 Recall: 0.875 F1 Score 0.875 AUROC: 0.848\n",
            "Epoch 040: Accuracy 0.890 Precision: 0.891 Recall: 0.890 F1 Score 0.891 AUROC: 0.864\n",
            "Epoch 050: Accuracy 0.882 Precision: 0.887 Recall: 0.882 F1 Score 0.884 AUROC: 0.865\n",
            "Epoch 060: Accuracy 0.845 Precision: 0.879 Recall: 0.845 F1 Score 0.852 AUROC: 0.867\n",
            "Epoch 070: Accuracy 0.907 Precision: 0.906 Recall: 0.907 F1 Score 0.906 AUROC: 0.870\n",
            "Epoch 080: Accuracy 0.908 Precision: 0.907 Recall: 0.908 F1 Score 0.908 AUROC: 0.878\n",
            "Epoch 090: Accuracy 0.903 Precision: 0.903 Recall: 0.903 F1 Score 0.903 AUROC: 0.873\n",
            "Epoch 100: Accuracy 0.889 Precision: 0.903 Recall: 0.889 F1 Score 0.893 AUROC: 0.895\n",
            "Epoch 110: Accuracy 0.909 Precision: 0.910 Recall: 0.909 F1 Score 0.910 AUROC: 0.890\n",
            "Epoch 120: Accuracy 0.900 Precision: 0.907 Recall: 0.900 F1 Score 0.902 AUROC: 0.894\n",
            "Epoch 130: Accuracy 0.910 Precision: 0.913 Recall: 0.910 F1 Score 0.911 AUROC: 0.899\n",
            "Epoch 140: Accuracy 0.921 Precision: 0.925 Recall: 0.921 F1 Score 0.922 AUROC: 0.915\n",
            "Epoch 150: Accuracy 0.902 Precision: 0.912 Recall: 0.902 F1 Score 0.904 AUROC: 0.904\n",
            "Epoch 160: Accuracy 0.921 Precision: 0.924 Recall: 0.921 F1 Score 0.922 AUROC: 0.910\n",
            "Epoch 170: Accuracy 0.925 Precision: 0.926 Recall: 0.925 F1 Score 0.926 AUROC: 0.911\n",
            "Epoch 180: Accuracy 0.904 Precision: 0.914 Recall: 0.904 F1 Score 0.906 AUROC: 0.907\n",
            "Epoch 190: Accuracy 0.916 Precision: 0.924 Recall: 0.916 F1 Score 0.918 AUROC: 0.919\n",
            "Epoch 200: Accuracy 0.930 Precision: 0.930 Recall: 0.930 F1 Score 0.930 AUROC: 0.911\n",
            "Epoch 210: Accuracy 0.932 Precision: 0.933 Recall: 0.932 F1 Score 0.933 AUROC: 0.916\n",
            "Epoch 220: Accuracy 0.930 Precision: 0.931 Recall: 0.930 F1 Score 0.931 AUROC: 0.916\n",
            "Epoch 230: Accuracy 0.933 Precision: 0.935 Recall: 0.933 F1 Score 0.934 AUROC: 0.926\n",
            "Epoch 240: Accuracy 0.931 Precision: 0.933 Recall: 0.931 F1 Score 0.932 AUROC: 0.921\n",
            "Epoch 250: Accuracy 0.912 Precision: 0.922 Recall: 0.912 F1 Score 0.915 AUROC: 0.918\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GAT(\n",
              "  (conv1): GATConv(22, 32, heads=4)\n",
              "  (conv2): GATConv(128, 32, heads=4)\n",
              "  (conv3): GATConv(128, 2, heads=1)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_results(GAT(), data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
